{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3e16b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ccba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TAXAGO_ASSETS_DIR = Path.home().joinpath(\".cargo\", \"taxago_assets\")\n",
    "LINEAGE_FILE = TAXAGO_ASSETS_DIR.joinpath(\"lineage.txt\")\n",
    "BACKGROUND_DIR = TAXAGO_ASSETS_DIR.joinpath(\"background_pop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_lineage_data(\n",
    "    lineage_file_path\n",
    "):\n",
    "    eukaryota_df = pd.read_csv(\n",
    "        lineage_file_path, \n",
    "        sep='\\t'\n",
    "    )\n",
    "    \n",
    "    for col in ['Superkingdom', 'Kingdom', 'Phylum', 'Class', 'Order', 'Family', 'Genus']:\n",
    "        eukaryota_df[col] = eukaryota_df[col].astype(str).str.strip()\n",
    "    \n",
    "    eukaryota = eukaryota_df[eukaryota_df['Superkingdom'].str.lower() == 'eukaryota'].copy()\n",
    "\n",
    "    print(f\"Filtered for Eukaryota: {len(eukaryota)} species.\")\n",
    "    return eukaryota\n",
    "\n",
    "def get_taxon_counts(\n",
    "    df, \n",
    "    rank_column, \n",
    "    parent_filters=None\n",
    "):\n",
    "\n",
    "    temp_df = df.copy()\n",
    "    if parent_filters:\n",
    "        for parent_rank, parent_name in parent_filters.items():\n",
    "            temp_df = temp_df[temp_df[parent_rank].str.lower() == parent_name.lower()]\n",
    "    \n",
    "    temp_df = temp_df[temp_df[rank_column].str.strip() != '']\n",
    "\n",
    "    return temp_df.groupby(rank_column)['Tax_ID'].nunique().sort_values(ascending=False)\n",
    "\n",
    "\n",
    "def sample_species(\n",
    "    df, \n",
    "    taxon_filters, \n",
    "    percentage_to_select,\n",
    "    max_species,\n",
    "    exclude_ids=None\n",
    "):\n",
    "    random.seed(42)\n",
    "    temp_df = df.copy()\n",
    "    for rank, name in taxon_filters.items():\n",
    "        temp_df = temp_df[temp_df[rank].str.lower() == name.lower()]\n",
    "\n",
    "    available_ids = temp_df['Tax_ID'].unique()\n",
    "    if exclude_ids:\n",
    "        available_ids = [tid for tid in available_ids if tid not in exclude_ids]\n",
    "\n",
    "    num_to_sample = min(int(len(available_ids) * (percentage_to_select / 100.0)), max_species)\n",
    "    num_to_sample = min(num_to_sample, len(available_ids))\n",
    "\n",
    "    return random.sample(list(available_ids), num_to_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d554828",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCENTAGE_PER_GROUP = 50.0\n",
    "MAX_SPECIES_PER_GROUP = 100\n",
    "\n",
    "all_final_species_lists = {}\n",
    "\n",
    "eukaryota_df = load_lineage_data(LINEAGE_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea42148",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Kingdom Selection (within Superkingdom: Eukaryota) ---\")\n",
    "kingdom_counts = get_taxon_counts(eukaryota_df, 'Kingdom')\n",
    "print(\"Top Kingdoms in Eukaryota (by species count):\\n\", kingdom_counts.head(10))\n",
    "\n",
    "K_IN_NAME = \"Metazoa\" \n",
    "K_OUT_NAME = \"Fungi\"\n",
    "\n",
    "print(f\"Chosen Ingroup Kingdom (Kingdom_in): {K_IN_NAME}\")\n",
    "print(f\"Chosen Outgroup Kingdom (Kingdom_out): {K_OUT_NAME}\")\n",
    "\n",
    "k_in_filters = {'Kingdom': K_IN_NAME}\n",
    "all_final_species_lists['Kingdom_in'] = sample_species(eukaryota_df, k_in_filters, PERCENTAGE_PER_GROUP, MAX_SPECIES_PER_GROUP)\n",
    "\n",
    "k_out_filters = {'Kingdom': K_OUT_NAME}\n",
    "all_final_species_lists['Kingdom_out'] = sample_species(eukaryota_df, k_out_filters, PERCENTAGE_PER_GROUP, MAX_SPECIES_PER_GROUP,\n",
    "                                                    exclude_ids=set(all_final_species_lists['Kingdom_in']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa81d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Phylum Selection (within Kingdom: {K_IN_NAME}) ---\")\n",
    "phylum_counts = get_taxon_counts(eukaryota_df, 'Phylum', {'Kingdom': K_IN_NAME})\n",
    "print(f\"Top Phyla in {K_IN_NAME} (by species count):\\n\", phylum_counts.head(10))\n",
    "\n",
    "P_IN_NAME = \"Chordata\" \n",
    "P_OUT_NAME = \"Arthropoda\"\n",
    "\n",
    "print(f\"Chosen Ingroup Phylum (Phylum_in): {P_IN_NAME} (within {K_IN_NAME})\")\n",
    "print(f\"Chosen Outgroup Phylum (Phylum_out): {P_OUT_NAME} (within {K_IN_NAME}, distinct from {P_IN_NAME})\")\n",
    "\n",
    "p_in_filters = {'Phylum': P_IN_NAME, 'Kingdom': K_IN_NAME}\n",
    "all_final_species_lists['Phylum_in'] = sample_species(eukaryota_df, p_in_filters, PERCENTAGE_PER_GROUP, MAX_SPECIES_PER_GROUP)\n",
    "\n",
    "p_out_filters = {'Phylum': P_OUT_NAME, 'Kingdom': K_IN_NAME}\n",
    "all_final_species_lists['Phylum_out'] = sample_species(eukaryota_df, p_out_filters, PERCENTAGE_PER_GROUP, MAX_SPECIES_PER_GROUP,\n",
    "                                                    exclude_ids=set(all_final_species_lists['Phylum_in']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04484f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Class Selection (within Phylum: {P_IN_NAME}) ---\")\n",
    "class_counts = get_taxon_counts(eukaryota_df, 'Class', {'Phylum': P_IN_NAME, 'Kingdom': K_IN_NAME})\n",
    "print(f\"Top Classes in {P_IN_NAME} (by species count):\\n\", class_counts.head(10))\n",
    "\n",
    "C_IN_NAME = \"Mammalia\" \n",
    "C_OUT_NAME = \"Aves\"    \n",
    "\n",
    "print(f\"Chosen Ingroup Class (Class_in): {C_IN_NAME} (within {P_IN_NAME})\")\n",
    "print(f\"Chosen Outgroup Class (Class_out): {C_OUT_NAME} (within {P_IN_NAME}, distinct from {C_IN_NAME})\")\n",
    "\n",
    "c_in_filters = {'Class': C_IN_NAME, 'Phylum': P_IN_NAME, 'Kingdom': K_IN_NAME}\n",
    "all_final_species_lists['Class_in'] = sample_species(eukaryota_df, c_in_filters, PERCENTAGE_PER_GROUP, MAX_SPECIES_PER_GROUP)\n",
    "\n",
    "c_out_filters = {'Class': C_OUT_NAME, 'Phylum': P_IN_NAME, 'Kingdom': K_IN_NAME}\n",
    "all_final_species_lists['Class_out'] = sample_species(eukaryota_df, c_out_filters, PERCENTAGE_PER_GROUP, MAX_SPECIES_PER_GROUP,\n",
    "                                                    exclude_ids=set(all_final_species_lists['Class_in']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72975242",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Order Selection (within Class: {C_IN_NAME}) ---\")\n",
    "order_counts = get_taxon_counts(eukaryota_df, 'Order', {'Class': C_IN_NAME, 'Phylum': P_IN_NAME, 'Kingdom': K_IN_NAME})\n",
    "print(f\"Top Orders in {C_IN_NAME} (by species count):\\n\", order_counts.head(10))\n",
    "\n",
    "O_IN_NAME = \"Primates\" \n",
    "O_OUT_NAME = \"Carnivora\" \n",
    "\n",
    "print(f\"Chosen Ingroup Order (Order_in): {O_IN_NAME} (within {C_IN_NAME})\")\n",
    "print(f\"Chosen Outgroup Order (Order_out): {O_OUT_NAME} (within {C_IN_NAME}, distinct from {O_IN_NAME})\")\n",
    "\n",
    "o_in_filters = {'Order': O_IN_NAME, 'Class': C_IN_NAME, 'Phylum': P_IN_NAME, 'Kingdom': K_IN_NAME}\n",
    "all_final_species_lists['Order_in'] = sample_species(eukaryota_df, o_in_filters, PERCENTAGE_PER_GROUP, MAX_SPECIES_PER_GROUP)\n",
    "\n",
    "o_out_filters = {'Order': O_OUT_NAME, 'Class': C_IN_NAME, 'Phylum': P_IN_NAME, 'Kingdom': K_IN_NAME}\n",
    "all_final_species_lists['Order_out'] = sample_species(eukaryota_df, o_out_filters, PERCENTAGE_PER_GROUP, MAX_SPECIES_PER_GROUP,\n",
    "                                                    exclude_ids=set(all_final_species_lists['Order_in']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453b9a3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- Selected Species Summary (Kingdom, Phylum, Class, Order) ---\")\n",
    "final_unique_species_overall = set()\n",
    "for group_label, tax_ids in all_final_species_lists.items():    \n",
    "    print(f\"Group '{group_label}': {len(tax_ids)} species selected.\")\n",
    "    final_unique_species_overall.update(tax_ids)\n",
    "\n",
    "print(f\"\\nTotal unique species selected across all defined groups: {len(final_unique_species_overall)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0694fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ingroup_membership(taxon_id, species_lists_dict):\n",
    "    \"\"\"Determines which ingroups a taxon_id belongs to based on provided lists.\"\"\"\n",
    "    member_of = []\n",
    "\n",
    "    if taxon_id in species_lists_dict.get('Order_in', []):\n",
    "        member_of.append('Order_in')\n",
    "    if taxon_id in species_lists_dict.get('Class_in', []):\n",
    "        member_of.append('Class_in')\n",
    "    if taxon_id in species_lists_dict.get('Phylum_in', []):\n",
    "        member_of.append('Phylum_in')\n",
    "    if taxon_id in species_lists_dict.get('Kingdom_in', []):\n",
    "        member_of.append('Kingdom_in')\n",
    "    return member_of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9a0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_taxon_background(\n",
    "    taxon_id, \n",
    "    background_dir\n",
    "):\n",
    "    proteome_annotations = collections.defaultdict(set)\n",
    "    filename = background_dir.joinpath(f\"{taxon_id}_background.txt\")\n",
    "            \n",
    "    with open(filename, 'rt') as f: \n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split('\\t')\n",
    "            if len(parts) >= 2:\n",
    "                protein_id, go_id = parts[0], parts[1]\n",
    "                proteome_annotations[protein_id].add(go_id)\n",
    "\n",
    "    return proteome_annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f9275c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_study_pop(\n",
    "    all_species_groups_dict: dict,\n",
    "    target_go_terms_map: dict,\n",
    "    background_dir: Path,\n",
    "    output_dir: Path,\n",
    "    proteome_percentage: float,\n",
    "    min_abs_study_size: int,\n",
    "    max_abs_study_size: int,\n",
    "    min_spike_in_percentage: float,\n",
    "    max_spike_in_percentage: float,\n",
    "    min_abs_spike_size: int,\n",
    "    max_abs_spike_size: int\n",
    "):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    random.seed(42)\n",
    "\n",
    "    all_unique_species_ids = set()\n",
    "    for id_list in all_species_groups_dict.values():\n",
    "        all_unique_species_ids.update(id_list)\n",
    "\n",
    "    species_to_study_proteins_map = {}\n",
    "\n",
    "    for species_id in all_unique_species_ids:\n",
    "        proteome_annotations = parse_taxon_background(species_id, background_dir)\n",
    "        all_protein_ids_in_proteome = list(proteome_annotations.keys())\n",
    "        num_proteins_in_proteome = len(all_protein_ids_in_proteome)\n",
    "\n",
    "        current_study_list_proteins_set = set()\n",
    "\n",
    "        calculated_study_list_size_from_percent = int(num_proteins_in_proteome * (proteome_percentage / 100.0))\n",
    "\n",
    "        actual_study_list_size_for_species = max(min_abs_study_size, calculated_study_list_size_from_percent)\n",
    "        actual_study_list_size_for_species = min(actual_study_list_size_for_species, max_abs_study_size)\n",
    "\n",
    "        actual_study_list_size_for_species = min(actual_study_list_size_for_species, num_proteins_in_proteome)\n",
    "\n",
    "        if num_proteins_in_proteome < actual_study_list_size_for_species or num_proteins_in_proteome < min_abs_study_size : \n",
    "            print(f\"  Note: Proteome for {species_id} ({num_proteins_in_proteome}) \"\n",
    "                  f\"is smaller than target study list size requirements. \"\n",
    "                  f\"Using all available proteins.\")\n",
    "            current_study_list_proteins_set = set(all_protein_ids_in_proteome)\n",
    "        else:\n",
    "            ingroup_levels = get_ingroup_membership(species_id, all_species_groups_dict)\n",
    "\n",
    "            target_gos_for_this_species_at_all_levels = []\n",
    "            for level in ingroup_levels: \n",
    "                if level in target_go_terms_map:\n",
    "                    target_gos_for_this_species_at_all_levels.extend(target_go_terms_map[level])\n",
    "\n",
    "            random.shuffle(target_gos_for_this_species_at_all_levels)\n",
    "\n",
    "            for target_go in target_gos_for_this_species_at_all_levels:\n",
    "                if len(current_study_list_proteins_set) >= actual_study_list_size_for_species:\n",
    "                    break \n",
    "\n",
    "                candidates_for_spike = [\n",
    "                    p_id for p_id in all_protein_ids_in_proteome \n",
    "                    if target_go in proteome_annotations.get(p_id, set()) and \\\n",
    "                       p_id not in current_study_list_proteins_set\n",
    "                ]\n",
    "                random.shuffle(candidates_for_spike)\n",
    "\n",
    "                calc_spike_min = int(actual_study_list_size_for_species * (min_spike_in_percentage / 100.0))\n",
    "                calc_spike_max = int(actual_study_list_size_for_species * (max_spike_in_percentage / 100.0))\n",
    "\n",
    "                current_spike_min = max(min_abs_spike_size, calc_spike_min)\n",
    "                current_spike_min = min(current_spike_min, max_abs_spike_size)\n",
    "\n",
    "                current_spike_max = max(min_abs_spike_size, calc_spike_max)\n",
    "                current_spike_max = min(current_spike_max, max_abs_spike_size)\n",
    "\n",
    "                if current_spike_max < current_spike_min:\n",
    "                    current_spike_max = current_spike_min\n",
    "\n",
    "\n",
    "                num_to_select_for_this_go = 0\n",
    "                if current_spike_min <= current_spike_max : \n",
    "                    num_to_select_for_this_go = random.randint(current_spike_min, current_spike_max)\n",
    "                else: \n",
    "                    num_to_select_for_this_go = current_spike_min\n",
    "\n",
    "\n",
    "                added_count_for_this_go = 0\n",
    "                for protein_to_add in candidates_for_spike:\n",
    "                    if len(current_study_list_proteins_set) >= actual_study_list_size_for_species: break\n",
    "                    if added_count_for_this_go >= num_to_select_for_this_go: break\n",
    "\n",
    "                    current_study_list_proteins_set.add(protein_to_add)\n",
    "                    added_count_for_this_go += 1\n",
    "\n",
    "            remaining_needed = actual_study_list_size_for_species - len(current_study_list_proteins_set)\n",
    "            if remaining_needed > 0:\n",
    "                other_available_proteins = [\n",
    "                    p_id for p_id in all_protein_ids_in_proteome \n",
    "                    if p_id not in current_study_list_proteins_set\n",
    "                ]\n",
    "                random.shuffle(other_available_proteins)\n",
    "\n",
    "                num_to_add_randomly = min(remaining_needed, len(other_available_proteins))\n",
    "                current_study_list_proteins_set.update(other_available_proteins[:num_to_add_randomly])\n",
    "\n",
    "            if len(current_study_list_proteins_set) < actual_study_list_size_for_species and \\\n",
    "               num_proteins_in_proteome >= actual_study_list_size_for_species :\n",
    "                 print(f\"  Warning: Final study list for {species_id} has \"\n",
    "                       f\"{len(current_study_list_proteins_set)}/{actual_study_list_size_for_species} proteins.\")\n",
    "\n",
    "        species_to_study_proteins_map[species_id] = sorted(list(current_study_list_proteins_set))\n",
    "\n",
    "    taxonomic_levels_for_files = [\"Kingdom\", \"Phylum\", \"Class\", \"Order\"]\n",
    "    for level_name in taxonomic_levels_for_files:\n",
    "        ingroup_key = f\"{level_name}_in\"\n",
    "        outgroup_key = f\"{level_name}_out\"\n",
    "\n",
    "        species_in_level_ingroup = all_species_groups_dict.get(ingroup_key, [])\n",
    "        species_in_level_outgroup = all_species_groups_dict.get(outgroup_key, [])\n",
    "\n",
    "        combined_species_for_csv_ordered = []\n",
    "        seen_species = set()\n",
    "        for sp_id in species_in_level_ingroup + species_in_level_outgroup:\n",
    "            if sp_id not in seen_species:\n",
    "                combined_species_for_csv_ordered.append(sp_id)\n",
    "                seen_species.add(sp_id)\n",
    "\n",
    "        data_for_df = {\n",
    "            species_id: species_to_study_proteins_map.get(species_id, [])\n",
    "            for species_id in combined_species_for_csv_ordered\n",
    "        }\n",
    "\n",
    "        df_level = pd.DataFrame(dict([ (k,pd.Series(v)) for k,v in data_for_df.items() ]))\n",
    "        csv_file_path = output_dir / f\"{level_name.lower()}.csv\"\n",
    "\n",
    "        df_level.to_csv(csv_file_path, index=False)\n",
    "        print(f\"Successfully wrote CSV: {csv_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb592f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_GO_TERMS = {\n",
    "    'O_in': ['GO:0060012', 'GO:1903974', 'GO:2000309', 'GO:1902613', 'GO:1901492'],\n",
    "    'C_in': ['GO:0140866', 'GO:0098940', 'GO:1901714', 'GO:1903168', 'GO:0106013'],\n",
    "    'P_in': ['GO:0007223', 'GO:1905381', 'GO:0062108', 'GO:0033147', 'GO:1903133'],\n",
    "    'K_in': ['GO:0110099', 'GO:2000845', 'GO:1904371', 'GO:0014718', 'GO:0048092']\n",
    "}\n",
    "\n",
    "PERCENT_OF_PROTEOME = 25.0\n",
    "MIN_ABS_STUDY_SIZE = 100\n",
    "MAX_ABS_STUDY_SIZE = 1000\n",
    "MIN_SPIKE_IN_PERCENTAGE = 5.0\n",
    "MAX_SPIKE_IN_PERCENTAGE = 10.0\n",
    "MIN_ABS_SPIKE_SIZE = 5\n",
    "MAX_ABS_SPIKE_SIZE = 15\n",
    "\n",
    "OUTPUT_DIR = Path().cwd().joinpath(\"synthetic_study_pop\")\n",
    "\n",
    "generate_study_pop(\n",
    "    all_species_groups_dict=all_final_species_lists,\n",
    "    target_go_terms_map=TARGET_GO_TERMS,\n",
    "    background_dir=BACKGROUND_DIR,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    proteome_percentage=PERCENT_OF_PROTEOME,\n",
    "    min_abs_study_size=MIN_ABS_STUDY_SIZE,\n",
    "    max_abs_study_size=MAX_ABS_STUDY_SIZE,\n",
    "    min_spike_in_percentage=MIN_SPIKE_IN_PERCENTAGE,\n",
    "    max_spike_in_percentage=MAX_SPIKE_IN_PERCENTAGE,\n",
    "    min_abs_spike_size=MIN_ABS_SPIKE_SIZE,\n",
    "    max_abs_spike_size=MAX_ABS_SPIKE_SIZE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lefteris",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
